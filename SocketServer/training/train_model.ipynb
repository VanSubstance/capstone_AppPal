{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2677, 5, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    'ONE',\n",
    "    'TWO',\n",
    "    'THREE',\n",
    "    'FOUR',\n",
    "    'FIVE',\n",
    "    'ZERO'\n",
    "]\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('dataset/seq_ONE_1662628138.npy'),\n",
    "    np.load('dataset/seq_TWO_1662628138.npy'),\n",
    "    np.load('dataset/seq_THREE_1662628138.npy'),\n",
    "    np.load('dataset/seq_FOUR_1662628138.npy'),\n",
    "    np.load('dataset/seq_FIVE_1662628138.npy'),\n",
    "    np.load('dataset/seq_ZERO_1662628138.npy')\n",
    "], axis=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2677, 5, 99)\n",
      "(2677,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2677, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2409, 5, 99) (2409, 6)\n",
      "(268, 5, 99) (268, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                41984     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,262\n",
      "Trainable params: 44,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 18:14:57.797780: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "64/76 [========================>.....] - ETA: 0s - loss: 2.6140 - acc: 0.7334\n",
      "Epoch 1: val_acc improved from -inf to 0.93284, saving model to models/model.h5\n",
      "76/76 [==============================] - 2s 7ms/step - loss: 2.2680 - acc: 0.7609 - val_loss: 0.2721 - val_acc: 0.9328 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.1494 - acc: 0.9556\n",
      "Epoch 2: val_acc improved from 0.93284 to 0.95149, saving model to models/model.h5\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.1494 - acc: 0.9556 - val_loss: 0.1642 - val_acc: 0.9515 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "73/76 [===========================>..] - ETA: 0s - loss: 0.0615 - acc: 0.9807\n",
      "Epoch 3: val_acc improved from 0.95149 to 0.96269, saving model to models/model.h5\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.0606 - acc: 0.9809 - val_loss: 0.1125 - val_acc: 0.9627 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "75/76 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9883\n",
      "Epoch 4: val_acc improved from 0.96269 to 0.98134, saving model to models/model.h5\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.0367 - acc: 0.9884 - val_loss: 0.0802 - val_acc: 0.9813 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "66/76 [=========================>....] - ETA: 0s - loss: 0.0226 - acc: 0.9948\n",
      "Epoch 5: val_acc did not improve from 0.98134\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.0225 - acc: 0.9946 - val_loss: 0.0842 - val_acc: 0.9664 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 0.0327 - acc: 0.9878\n",
      "Epoch 6: val_acc improved from 0.98134 to 0.99254, saving model to models/model.h5\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.0300 - acc: 0.9884 - val_loss: 0.0352 - val_acc: 0.9925 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "69/76 [==========================>...] - ETA: 0s - loss: 0.0096 - acc: 0.9950 \n",
      "Epoch 7: val_acc did not improve from 0.99254\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.0095 - acc: 0.9954 - val_loss: 0.0348 - val_acc: 0.9813 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 0.0069 - acc: 0.9973\n",
      "Epoch 8: val_acc improved from 0.99254 to 0.99627, saving model to models/model.h5\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.0057 - acc: 0.9979 - val_loss: 0.0225 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "57/76 [=====================>........] - ETA: 0s - loss: 0.0012 - acc: 1.0000    \n",
      "Epoch 9: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0287 - val_acc: 0.9888 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "75/76 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9987\n",
      "Epoch 10: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0197 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "57/76 [=====================>........] - ETA: 0s - loss: 9.0828e-04 - acc: 1.0000\n",
      "Epoch 11: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 8.8285e-04 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 6.7038e-04 - acc: 1.0000\n",
      "Epoch 12: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 7.3114e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "75/76 [============================>.] - ETA: 0s - loss: 4.2073e-04 - acc: 1.0000\n",
      "Epoch 13: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 4.1930e-04 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 0.9925 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "57/76 [=====================>........] - ETA: 0s - loss: 2.8674e-04 - acc: 1.0000\n",
      "Epoch 14: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.7685e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 1.6490e-04 - acc: 1.0000\n",
      "Epoch 15: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.6052e-04 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 1.4226e-04 - acc: 1.0000\n",
      "Epoch 16: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.4226e-04 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 1.2528e-04 - acc: 1.0000\n",
      "Epoch 17: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.2017e-04 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 9.8571e-05 - acc: 1.0000\n",
      "Epoch 18: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 9.8290e-05 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 8.4479e-05 - acc: 1.0000\n",
      "Epoch 19: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 8.5875e-05 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "62/76 [=======================>......] - ETA: 0s - loss: 7.0816e-05 - acc: 1.0000\n",
      "Epoch 20: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 7.4705e-05 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "56/76 [=====================>........] - ETA: 0s - loss: 6.7546e-05 - acc: 1.0000\n",
      "Epoch 21: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 6.5194e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 5.3429e-05 - acc: 1.0000\n",
      "Epoch 22: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 5.7785e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 5.5237e-05 - acc: 1.0000\n",
      "Epoch 23: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 5.0762e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 4.4871e-05 - acc: 1.0000\n",
      "Epoch 24: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 4.5925e-05 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "75/76 [============================>.] - ETA: 0s - loss: 4.0871e-05 - acc: 1.0000\n",
      "Epoch 25: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 4.0737e-05 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "62/76 [=======================>......] - ETA: 0s - loss: 3.5342e-05 - acc: 1.0000\n",
      "Epoch 26: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.6537e-05 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 3.5110e-05 - acc: 1.0000\n",
      "Epoch 27: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.2969e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 3.1811e-05 - acc: 1.0000\n",
      "Epoch 28: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.9994e-05 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 2.8957e-05 - acc: 1.0000\n",
      "Epoch 29: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.7104e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "75/76 [============================>.] - ETA: 0s - loss: 2.5947e-05 - acc: 1.0000\n",
      "Epoch 30: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.5862e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 2.1935e-05 - acc: 1.0000\n",
      "Epoch 31: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.2710e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 2.1119e-05 - acc: 1.0000\n",
      "Epoch 32: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.0135e-05 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 1.9693e-05 - acc: 1.0000\n",
      "Epoch 33: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.8373e-05 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "64/76 [========================>.....] - ETA: 0s - loss: 1.8326e-05 - acc: 1.0000\n",
      "Epoch 34: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 1.7090e-05 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "73/76 [===========================>..] - ETA: 0s - loss: 1.5585e-05 - acc: 1.0000\n",
      "Epoch 35: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 1.5662e-05 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "64/76 [========================>.....] - ETA: 0s - loss: 1.3123e-05 - acc: 1.0000\n",
      "Epoch 36: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 1.4328e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 1.1066e-05 - acc: 1.0000\n",
      "Epoch 37: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 1.3485e-05 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "69/76 [==========================>...] - ETA: 0s - loss: 1.3365e-05 - acc: 1.0000\n",
      "Epoch 38: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.2653e-05 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "66/76 [=========================>....] - ETA: 0s - loss: 1.2010e-05 - acc: 1.0000\n",
      "Epoch 39: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.1782e-05 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "66/76 [=========================>....] - ETA: 0s - loss: 1.2046e-05 - acc: 1.0000\n",
      "Epoch 40: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.1235e-05 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "66/76 [=========================>....] - ETA: 0s - loss: 9.9009e-06 - acc: 1.0000\n",
      "Epoch 41: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.0501e-05 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 9.6255e-06 - acc: 1.0000\n",
      "Epoch 42: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 9.8878e-06 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "69/76 [==========================>...] - ETA: 0s - loss: 9.0250e-06 - acc: 1.0000\n",
      "Epoch 43: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 9.2328e-06 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 8.8385e-06 - acc: 1.0000\n",
      "Epoch 44: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 8.7513e-06 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "66/76 [=========================>....] - ETA: 0s - loss: 7.8264e-06 - acc: 1.0000\n",
      "Epoch 45: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 8.3721e-06 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 7.8413e-06 - acc: 1.0000\n",
      "Epoch 46: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 7.8106e-06 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 6.8517e-06 - acc: 1.0000\n",
      "Epoch 47: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 7.4187e-06 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "65/76 [========================>.....] - ETA: 0s - loss: 7.4645e-06 - acc: 1.0000\n",
      "Epoch 48: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 7.0468e-06 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "74/76 [============================>.] - ETA: 0s - loss: 6.7472e-06 - acc: 1.0000\n",
      "Epoch 49: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 6.6632e-06 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 5.7686e-06 - acc: 1.0000\n",
      "Epoch 50: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 6.3038e-06 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 5.4835e-06 - acc: 1.0000\n",
      "Epoch 51: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 6.0043e-06 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 5.6935e-06 - acc: 1.0000\n",
      "Epoch 52: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 5.7160e-06 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "69/76 [==========================>...] - ETA: 0s - loss: 5.8592e-06 - acc: 1.0000\n",
      "Epoch 53: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 5.5510e-06 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 5.1144e-06 - acc: 1.0000\n",
      "Epoch 54: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 5.1539e-06 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 4.0232e-06 - acc: 1.0000\n",
      "Epoch 55: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 4.8583e-06 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 4.8392e-06 - acc: 1.0000\n",
      "Epoch 56: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 4.6531e-06 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "72/76 [===========================>..] - ETA: 0s - loss: 4.5703e-06 - acc: 1.0000\n",
      "Epoch 57: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 4.4560e-06 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 4.3007e-06 - acc: 1.0000\n",
      "Epoch 58: val_acc did not improve from 0.99627\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 4.2425e-06 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "62/76 [=======================>......] - ETA: 0s - loss: 4.0087e-06 - acc: 1.0000\n",
      "Epoch 59: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 4.0150e-06 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 60/200\n",
      "65/76 [========================>.....] - ETA: 0s - loss: 3.4140e-06 - acc: 1.0000\n",
      "Epoch 60: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.9148e-06 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 61/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 2.9843e-06 - acc: 1.0000\n",
      "Epoch 61: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.8106e-06 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 62/200\n",
      "74/76 [============================>.] - ETA: 0s - loss: 3.8075e-06 - acc: 1.0000\n",
      "Epoch 62: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.7537e-06 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 63/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 3.4892e-06 - acc: 1.0000\n",
      "Epoch 63: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 3.6411e-06 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 64/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 3.5721e-06 - acc: 1.0000\n",
      "Epoch 64: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.5309e-06 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 65/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 3.7080e-06 - acc: 1.0000\n",
      "Epoch 65: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.4599e-06 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 66/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 3.4623e-06 - acc: 1.0000\n",
      "Epoch 66: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.3493e-06 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "70/76 [==========================>...] - ETA: 0s - loss: 3.1010e-06 - acc: 1.0000\n",
      "Epoch 67: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 3.2578e-06 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "73/76 [===========================>..] - ETA: 0s - loss: 3.2460e-06 - acc: 1.0000\n",
      "Epoch 68: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.1671e-06 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "62/76 [=======================>......] - ETA: 0s - loss: 2.9836e-06 - acc: 1.0000\n",
      "Epoch 69: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 3.0867e-06 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "73/76 [===========================>..] - ETA: 0s - loss: 2.7991e-06 - acc: 1.0000\n",
      "Epoch 70: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.9945e-06 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 2.9161e-06 - acc: 1.0000\n",
      "Epoch 71: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.9161e-06 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 2.9536e-06 - acc: 1.0000\n",
      "Epoch 72: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.8321e-06 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 2.4209e-06 - acc: 1.0000\n",
      "Epoch 73: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.7584e-06 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 2.5197e-06 - acc: 1.0000\n",
      "Epoch 74: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.6819e-06 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "69/76 [==========================>...] - ETA: 0s - loss: 2.6409e-06 - acc: 1.0000\n",
      "Epoch 75: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 2.5887e-06 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "69/76 [==========================>...] - ETA: 0s - loss: 2.6270e-06 - acc: 1.0000\n",
      "Epoch 76: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 2.5121e-06 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "74/76 [============================>.] - ETA: 0s - loss: 2.4749e-06 - acc: 1.0000\n",
      "Epoch 77: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 2.4512e-06 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "74/76 [============================>.] - ETA: 0s - loss: 2.3441e-06 - acc: 1.0000\n",
      "Epoch 78: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 2.3665e-06 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 2.3993e-06 - acc: 1.0000\n",
      "Epoch 79: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.2881e-06 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 2.1598e-06 - acc: 1.0000\n",
      "Epoch 80: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.2194e-06 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "68/76 [=========================>....] - ETA: 0s - loss: 2.1866e-06 - acc: 1.0000\n",
      "Epoch 81: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.1572e-06 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 1.9664e-06 - acc: 1.0000\n",
      "Epoch 82: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.0914e-06 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "68/76 [=========================>....] - ETA: 0s - loss: 2.1002e-06 - acc: 1.0000\n",
      "Epoch 83: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.0361e-06 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 2.0089e-06 - acc: 1.0000\n",
      "Epoch 84: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.9606e-06 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 1.7707e-06 - acc: 1.0000\n",
      "Epoch 85: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.9049e-06 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "71/76 [===========================>..] - ETA: 0s - loss: 1.6576e-06 - acc: 1.0000\n",
      "Epoch 86: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.8428e-06 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "71/76 [===========================>..] - ETA: 0s - loss: 1.7062e-06 - acc: 1.0000\n",
      "Epoch 87: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 1.7808e-06 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "70/76 [==========================>...] - ETA: 0s - loss: 1.7737e-06 - acc: 1.0000\n",
      "Epoch 88: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 1.7200e-06 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "66/76 [=========================>....] - ETA: 0s - loss: 1.6476e-06 - acc: 1.0000\n",
      "Epoch 89: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 1.6744e-06 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 1.7135e-06 - acc: 1.0000\n",
      "Epoch 90: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 1.6102e-06 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "71/76 [===========================>..] - ETA: 0s - loss: 1.5249e-06 - acc: 1.0000\n",
      "Epoch 91: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.4979e-06 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 1.2474e-06 - acc: 1.0000\n",
      "Epoch 92: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 1.4408e-06 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "71/76 [===========================>..] - ETA: 0s - loss: 1.4498e-06 - acc: 1.0000\n",
      "Epoch 93: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 1.3853e-06 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 1.3426e-06 - acc: 1.0000\n",
      "Epoch 94: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.3426e-06 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "72/76 [===========================>..] - ETA: 0s - loss: 1.3074e-06 - acc: 1.0000\n",
      "Epoch 95: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.2886e-06 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "70/76 [==========================>...] - ETA: 0s - loss: 1.0768e-06 - acc: 1.0000\n",
      "Epoch 96: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 1.2440e-06 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "69/76 [==========================>...] - ETA: 0s - loss: 1.2571e-06 - acc: 1.0000\n",
      "Epoch 97: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.1999e-06 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 1.1809e-06 - acc: 1.0000\n",
      "Epoch 98: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.1543e-06 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "62/76 [=======================>......] - ETA: 0s - loss: 9.4776e-07 - acc: 1.0000\n",
      "Epoch 99: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.1133e-06 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "68/76 [=========================>....] - ETA: 0s - loss: 1.0937e-06 - acc: 1.0000\n",
      "Epoch 100: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.0745e-06 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "66/76 [=========================>....] - ETA: 0s - loss: 9.9737e-07 - acc: 1.0000\n",
      "Epoch 101: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.0399e-06 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 9.8949e-07 - acc: 1.0000\n",
      "Epoch 102: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.0154e-06 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "68/76 [=========================>....] - ETA: 0s - loss: 9.5982e-07 - acc: 1.0000\n",
      "Epoch 103: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 9.8179e-07 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 9.3329e-07 - acc: 1.0000\n",
      "Epoch 104: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 9.1687e-07 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 8.9832e-07 - acc: 1.0000\n",
      "Epoch 105: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 8.8451e-07 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 8.0291e-07 - acc: 1.0000\n",
      "Epoch 106: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 8.4443e-07 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 8.7247e-07 - acc: 1.0000\n",
      "Epoch 107: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 8.1420e-07 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 108/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 7.8178e-07 - acc: 1.0000\n",
      "Epoch 108: val_acc did not improve from 0.99627\n",
      "\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 7.8471e-07 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "57/76 [=====================>........] - ETA: 0s - loss: 6.7145e-07 - acc: 1.0000\n",
      "Epoch 109: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 7.4972e-07 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 110/200\n",
      "68/76 [=========================>....] - ETA: 0s - loss: 7.0115e-07 - acc: 1.0000\n",
      "Epoch 110: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 7.3587e-07 - acc: 1.0000 - val_loss: 0.0258 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 111/200\n",
      "69/76 [==========================>...] - ETA: 0s - loss: 6.6314e-07 - acc: 1.0000\n",
      "Epoch 111: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 7.2211e-07 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 112/200\n",
      "63/76 [=======================>......] - ETA: 0s - loss: 7.4716e-07 - acc: 1.0000\n",
      "Epoch 112: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 7.0682e-07 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 113/200\n",
      "68/76 [=========================>....] - ETA: 0s - loss: 6.9075e-07 - acc: 1.0000\n",
      "Epoch 113: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 6.9044e-07 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 114/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 6.3101e-07 - acc: 1.0000\n",
      "Epoch 114: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 6.7911e-07 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 115/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 7.0067e-07 - acc: 1.0000\n",
      "Epoch 115: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 6.6486e-07 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 116/200\n",
      "69/76 [==========================>...] - ETA: 0s - loss: 6.6886e-07 - acc: 1.0000\n",
      "Epoch 116: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 6.4932e-07 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 117/200\n",
      "63/76 [=======================>......] - ETA: 0s - loss: 6.8762e-07 - acc: 1.0000\n",
      "Epoch 117: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 6.3413e-07 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 118/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 6.4101e-07 - acc: 1.0000\n",
      "Epoch 118: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 6.1998e-07 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 119/200\n",
      "63/76 [=======================>......] - ETA: 0s - loss: 6.0200e-07 - acc: 1.0000\n",
      "Epoch 119: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 6.0326e-07 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 120/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 5.9325e-07 - acc: 1.0000\n",
      "Epoch 120: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 5.9524e-07 - acc: 1.0000 - val_loss: 0.0311 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 121/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 5.5346e-07 - acc: 1.0000\n",
      "Epoch 121: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 5.7693e-07 - acc: 1.0000 - val_loss: 0.0318 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 122/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 5.3874e-07 - acc: 1.0000\n",
      "Epoch 122: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 5.6199e-07 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 123/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 5.9404e-07 - acc: 1.0000\n",
      "Epoch 123: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 5.4853e-07 - acc: 1.0000 - val_loss: 0.0337 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 124/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 5.3566e-07 - acc: 1.0000\n",
      "Epoch 124: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 5.3566e-07 - acc: 1.0000 - val_loss: 0.0349 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 125/200\n",
      "74/76 [============================>.] - ETA: 0s - loss: 4.9953e-07 - acc: 1.0000\n",
      "Epoch 125: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 5.1721e-07 - acc: 1.0000 - val_loss: 0.0349 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 126/200\n",
      "62/76 [=======================>......] - ETA: 0s - loss: 5.0495e-07 - acc: 1.0000\n",
      "Epoch 126: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 4.9672e-07 - acc: 1.0000 - val_loss: 0.0367 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 127/200\n",
      "69/76 [==========================>...] - ETA: 0s - loss: 4.6376e-07 - acc: 1.0000\n",
      "Epoch 127: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 4.8608e-07 - acc: 1.0000 - val_loss: 0.0368 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 128/200\n",
      "72/76 [===========================>..] - ETA: 0s - loss: 4.6674e-07 - acc: 1.0000\n",
      "Epoch 128: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 4.6876e-07 - acc: 1.0000 - val_loss: 0.0367 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 129/200\n",
      "73/76 [===========================>..] - ETA: 0s - loss: 4.6315e-07 - acc: 1.0000\n",
      "Epoch 129: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 4.5322e-07 - acc: 1.0000 - val_loss: 0.0398 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 130/200\n",
      "65/76 [========================>.....] - ETA: 0s - loss: 4.6044e-07 - acc: 1.0000\n",
      "Epoch 130: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 4.3393e-07 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 131/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 4.1728e-07 - acc: 1.0000\n",
      "Epoch 131: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 4.2146e-07 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 132/200\n",
      "72/76 [===========================>..] - ETA: 0s - loss: 3.3326e-07 - acc: 1.0000\n",
      "Epoch 132: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 4.0656e-07 - acc: 1.0000 - val_loss: 0.0422 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 133/200\n",
      "75/76 [============================>.] - ETA: 0s - loss: 3.9284e-07 - acc: 1.0000\n",
      "Epoch 133: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 3.9137e-07 - acc: 1.0000 - val_loss: 0.0428 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 134/200\n",
      "71/76 [===========================>..] - ETA: 0s - loss: 3.7525e-07 - acc: 1.0000\n",
      "Epoch 134: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.7598e-07 - acc: 1.0000 - val_loss: 0.0465 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 135/200\n",
      "74/76 [============================>.] - ETA: 0s - loss: 3.5938e-07 - acc: 1.0000\n",
      "Epoch 135: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.6188e-07 - acc: 1.0000 - val_loss: 0.0437 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 136/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 2.9367e-07 - acc: 1.0000\n",
      "Epoch 136: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.5352e-07 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 137/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 3.6544e-07 - acc: 1.0000\n",
      "Epoch 137: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.3971e-07 - acc: 1.0000 - val_loss: 0.0436 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 138/200\n",
      "74/76 [============================>.] - ETA: 0s - loss: 3.2999e-07 - acc: 1.0000\n",
      "Epoch 138: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.2477e-07 - acc: 1.0000 - val_loss: 0.0457 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 139/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 3.3515e-07 - acc: 1.0000\n",
      "Epoch 139: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.0943e-07 - acc: 1.0000 - val_loss: 0.0484 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 140/200\n",
      "67/76 [=========================>....] - ETA: 0s - loss: 3.0280e-07 - acc: 1.0000\n",
      "Epoch 140: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 3.0126e-07 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 141/200\n",
      "57/76 [=====================>........] - ETA: 0s - loss: 2.7495e-07 - acc: 1.0000\n",
      "Epoch 141: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.8978e-07 - acc: 1.0000 - val_loss: 0.0486 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 142/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 2.4978e-07 - acc: 1.0000\n",
      "Epoch 142: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.7889e-07 - acc: 1.0000 - val_loss: 0.0481 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 143/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 2.8000e-07 - acc: 1.0000\n",
      "Epoch 143: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.6593e-07 - acc: 1.0000 - val_loss: 0.0502 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 144/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 2.5890e-07 - acc: 1.0000\n",
      "Epoch 144: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.5890e-07 - acc: 1.0000 - val_loss: 0.0514 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 145/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 2.6946e-07 - acc: 1.0000\n",
      "Epoch 145: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.4430e-07 - acc: 1.0000 - val_loss: 0.0513 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 146/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 2.6529e-07 - acc: 1.0000\n",
      "Epoch 146: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.3337e-07 - acc: 1.0000 - val_loss: 0.0528 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 147/200\n",
      "66/76 [=========================>....] - ETA: 0s - loss: 2.3006e-07 - acc: 1.0000\n",
      "Epoch 147: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 2.2614e-07 - acc: 1.0000 - val_loss: 0.0543 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 148/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 2.4220e-07 - acc: 1.0000\n",
      "Epoch 148: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.1808e-07 - acc: 1.0000 - val_loss: 0.0531 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 149/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 2.2215e-07 - acc: 1.0000\n",
      "Epoch 149: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 2.0972e-07 - acc: 1.0000 - val_loss: 0.0536 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 150/200\n",
      "56/76 [=====================>........] - ETA: 0s - loss: 1.7017e-07 - acc: 1.0000\n",
      "Epoch 150: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.9828e-07 - acc: 1.0000 - val_loss: 0.0564 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 151/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 1.9346e-07 - acc: 1.0000\n",
      "Epoch 151: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.9502e-07 - acc: 1.0000 - val_loss: 0.0561 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 152/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 1.8359e-07 - acc: 1.0000\n",
      "Epoch 152: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.8393e-07 - acc: 1.0000 - val_loss: 0.0563 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 153/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 1.7859e-07 - acc: 1.0000\n",
      "Epoch 153: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.7859e-07 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 154/200\n",
      "70/76 [==========================>...] - ETA: 0s - loss: 1.6556e-07 - acc: 1.0000\n",
      "Epoch 154: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 1.6835e-07 - acc: 1.0000 - val_loss: 0.0605 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 155/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 1.6546e-07 - acc: 1.0000\n",
      "Epoch 155: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.6038e-07 - acc: 1.0000 - val_loss: 0.0626 - val_acc: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 156/200\n",
      "56/76 [=====================>........] - ETA: 0s - loss: 1.5214e-07 - acc: 1.0000\n",
      "Epoch 156: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.5711e-07 - acc: 1.0000 - val_loss: 0.0580 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 157/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 1.3150e-07 - acc: 1.0000\n",
      "Epoch 157: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.4633e-07 - acc: 1.0000 - val_loss: 0.0628 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 158/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 1.4623e-07 - acc: 1.0000\n",
      "Epoch 158: val_acc did not improve from 0.99627\n",
      "\n",
      "Epoch 158: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.3940e-07 - acc: 1.0000 - val_loss: 0.0618 - val_acc: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 159/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 1.3222e-07 - acc: 1.0000\n",
      "Epoch 159: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.3222e-07 - acc: 1.0000 - val_loss: 0.0604 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 160/200\n",
      "57/76 [=====================>........] - ETA: 0s - loss: 1.2483e-07 - acc: 1.0000\n",
      "Epoch 160: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.2935e-07 - acc: 1.0000 - val_loss: 0.0625 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 161/200\n",
      "66/76 [=========================>....] - ETA: 0s - loss: 1.3434e-07 - acc: 1.0000\n",
      "Epoch 161: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 1.2604e-07 - acc: 1.0000 - val_loss: 0.0607 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 162/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 1.3916e-07 - acc: 1.0000\n",
      "Epoch 162: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.2312e-07 - acc: 1.0000 - val_loss: 0.0626 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 163/200\n",
      "63/76 [=======================>......] - ETA: 0s - loss: 1.2613e-07 - acc: 1.0000\n",
      "Epoch 163: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.2079e-07 - acc: 1.0000 - val_loss: 0.0620 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 164/200\n",
      "70/76 [==========================>...] - ETA: 0s - loss: 1.1937e-07 - acc: 1.0000\n",
      "Epoch 164: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.1723e-07 - acc: 1.0000 - val_loss: 0.0616 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 165/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 1.2186e-07 - acc: 1.0000\n",
      "Epoch 165: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.1446e-07 - acc: 1.0000 - val_loss: 0.0621 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 166/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 1.2306e-07 - acc: 1.0000\n",
      "Epoch 166: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.1164e-07 - acc: 1.0000 - val_loss: 0.0626 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 167/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 1.2441e-07 - acc: 1.0000\n",
      "Epoch 167: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.0916e-07 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 168/200\n",
      "66/76 [=========================>....] - ETA: 0s - loss: 1.1706e-07 - acc: 1.0000\n",
      "Epoch 168: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 1.0644e-07 - acc: 1.0000 - val_loss: 0.0619 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 169/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 1.0342e-07 - acc: 1.0000\n",
      "Epoch 169: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.0342e-07 - acc: 1.0000 - val_loss: 0.0634 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 170/200\n",
      "62/76 [=======================>......] - ETA: 0s - loss: 1.1831e-07 - acc: 1.0000\n",
      "Epoch 170: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 1.0199e-07 - acc: 1.0000 - val_loss: 0.0649 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 171/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 7.5189e-08 - acc: 1.0000\n",
      "Epoch 171: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 9.7435e-08 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 172/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 9.5258e-08 - acc: 1.0000\n",
      "Epoch 172: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 9.5258e-08 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 173/200\n",
      "74/76 [============================>.] - ETA: 0s - loss: 9.1420e-08 - acc: 1.0000\n",
      "Epoch 173: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 9.2240e-08 - acc: 1.0000 - val_loss: 0.0647 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 174/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 9.9888e-08 - acc: 1.0000\n",
      "Epoch 174: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 8.9320e-08 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 175/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 1.0277e-07 - acc: 1.0000\n",
      "Epoch 175: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 8.7440e-08 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 176/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 9.4352e-08 - acc: 1.0000\n",
      "Epoch 176: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 8.4866e-08 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 177/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 8.8491e-08 - acc: 1.0000\n",
      "Epoch 177: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 8.1947e-08 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 178/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 9.0323e-08 - acc: 1.0000\n",
      "Epoch 178: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 8.0314e-08 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 179/200\n",
      "57/76 [=====================>........] - ETA: 0s - loss: 8.4962e-08 - acc: 1.0000\n",
      "Epoch 179: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 7.8136e-08 - acc: 1.0000 - val_loss: 0.0679 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 180/200\n",
      "62/76 [=======================>......] - ETA: 0s - loss: 7.9072e-08 - acc: 1.0000\n",
      "Epoch 180: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 7.4870e-08 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 181/200\n",
      "62/76 [=======================>......] - ETA: 0s - loss: 7.6789e-08 - acc: 1.0000\n",
      "Epoch 181: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 7.3485e-08 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 182/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 7.9515e-08 - acc: 1.0000\n",
      "Epoch 182: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 7.0367e-08 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 183/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 7.3558e-08 - acc: 1.0000\n",
      "Epoch 183: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 6.8784e-08 - acc: 1.0000 - val_loss: 0.0688 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 184/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 7.1086e-08 - acc: 1.0000\n",
      "Epoch 184: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 6.8437e-08 - acc: 1.0000 - val_loss: 0.0673 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 185/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 5.5121e-08 - acc: 1.0000\n",
      "Epoch 185: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 6.3984e-08 - acc: 1.0000 - val_loss: 0.0701 - val_acc: 0.9851 - lr: 1.2500e-04\n",
      "Epoch 186/200\n",
      "71/76 [===========================>..] - ETA: 0s - loss: 6.1493e-08 - acc: 1.0000\n",
      "Epoch 186: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 6.1658e-08 - acc: 1.0000 - val_loss: 0.0718 - val_acc: 0.9851 - lr: 1.2500e-04\n",
      "Epoch 187/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 6.8128e-08 - acc: 1.0000\n",
      "Epoch 187: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 6.0817e-08 - acc: 1.0000 - val_loss: 0.0692 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 188/200\n",
      "61/76 [=======================>......] - ETA: 0s - loss: 4.8978e-08 - acc: 1.0000\n",
      "Epoch 188: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 5.8392e-08 - acc: 1.0000 - val_loss: 0.0696 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 189/200\n",
      "58/76 [=====================>........] - ETA: 0s - loss: 6.3522e-08 - acc: 1.0000\n",
      "Epoch 189: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 5.6462e-08 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 190/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 5.1223e-08 - acc: 1.0000\n",
      "Epoch 190: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 5.4285e-08 - acc: 1.0000 - val_loss: 0.0712 - val_acc: 0.9851 - lr: 1.2500e-04\n",
      "Epoch 191/200\n",
      "73/76 [===========================>..] - ETA: 0s - loss: 5.3889e-08 - acc: 1.0000\n",
      "Epoch 191: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 5.2850e-08 - acc: 1.0000 - val_loss: 0.0727 - val_acc: 0.9851 - lr: 1.2500e-04\n",
      "Epoch 192/200\n",
      "75/76 [============================>.] - ETA: 0s - loss: 4.6988e-08 - acc: 1.0000\n",
      "Epoch 192: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 5.0771e-08 - acc: 1.0000 - val_loss: 0.0709 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 193/200\n",
      "72/76 [===========================>..] - ETA: 0s - loss: 5.1326e-08 - acc: 1.0000\n",
      "Epoch 193: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 4.9881e-08 - acc: 1.0000 - val_loss: 0.0699 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 194/200\n",
      "60/76 [======================>.......] - ETA: 0s - loss: 3.5949e-08 - acc: 1.0000\n",
      "Epoch 194: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 4.6813e-08 - acc: 1.0000 - val_loss: 0.0728 - val_acc: 0.9851 - lr: 1.2500e-04\n",
      "Epoch 195/200\n",
      "75/76 [============================>.] - ETA: 0s - loss: 4.5101e-08 - acc: 1.0000\n",
      "Epoch 195: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 4.4932e-08 - acc: 1.0000 - val_loss: 0.0723 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 196/200\n",
      "59/76 [======================>.......] - ETA: 0s - loss: 4.8113e-08 - acc: 1.0000\n",
      "Epoch 196: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 4.3844e-08 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 197/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 4.2161e-08 - acc: 1.0000\n",
      "Epoch 197: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 4.2161e-08 - acc: 1.0000 - val_loss: 0.0724 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 198/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 4.0231e-08 - acc: 1.0000\n",
      "Epoch 198: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 4.0231e-08 - acc: 1.0000 - val_loss: 0.0722 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 199/200\n",
      "75/76 [============================>.] - ETA: 0s - loss: 3.8892e-08 - acc: 1.0000\n",
      "Epoch 199: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.8747e-08 - acc: 1.0000 - val_loss: 0.0710 - val_acc: 0.9888 - lr: 1.2500e-04\n",
      "Epoch 200/200\n",
      "62/76 [=======================>......] - ETA: 0s - loss: 3.1064e-08 - acc: 1.0000\n",
      "Epoch 200: val_acc did not improve from 0.99627\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 3.8202e-08 - acc: 1.0000 - val_loss: 0.0699 - val_acc: 0.9888 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[220,   0],\n",
       "        [  1,  47]],\n",
       "\n",
       "       [[223,   0],\n",
       "        [  0,  45]],\n",
       "\n",
       "       [[218,   0],\n",
       "        [  0,  50]],\n",
       "\n",
       "       [[227,   0],\n",
       "        [  0,  41]],\n",
       "\n",
       "       [[226,   0],\n",
       "        [  0,  42]],\n",
       "\n",
       "       [[225,   1],\n",
       "        [  0,  42]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
